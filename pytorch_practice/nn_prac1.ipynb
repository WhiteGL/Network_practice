{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 \u003d nn.Conv2d(1, 6, 5)\n        self.conv2 \u003d nn.Conv2d(6, 16, 5)\n        # add linear operation\n        self.fc1 \u003d nn.Linear(16 * 5 * 5, 120)\n        self.fc2 \u003d nn.Linear(120, 84)\n        self.fc3 \u003d nn.Linear(84, 10)\n\n    def forward(self, x):\n        # 2x2 max pooling\n        x \u003d F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # 方阵可用 2 代替 （2,2）\n        x \u003d F.max_pool2d(F.relu((self.conv2(x))), 2)\n        x \u003d x.view(-1, self.num_flat_features(x))\n        x \u003d F.relu(self.fc1(x))\n        x \u003d F.relu(self.fc2(x))\n        x \u003d self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size \u003d x.size()[1:]\n        num_features \u003d 1\n        for s in size:\n            num_features *\u003d s\n        return num_features\n\n\nnet \u003d Net()\nprint(net)\n"
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}