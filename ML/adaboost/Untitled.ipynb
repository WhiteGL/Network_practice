{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "def loadDataSet(fileName):\n",
    "    numberFeat = len(open(fileName).readline().split('\\t')) - 1\n",
    "    dataSet = []\n",
    "    labelSet = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        # 去掉收尾空格，分隔每一列\n",
    "        curLine = line.strip().split('\\t')\n",
    "        # 保存每一列特征数据\n",
    "        for i in range(numberFeat):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataSet.append(lineArr)\n",
    "        labelSet.append(float(curLine[-1]))\n",
    "    return dataSet, labelSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个分类器的决策实现\n",
    "def stumpClassify(dataMatrix, columnIndex, threshVal, threshIneq):\n",
    "    # init\n",
    "    retLabelArray = np.ones(np.shape(dataMatrix)[0], 1)\n",
    "    # less than\n",
    "    if threshIneq == 'lt':\n",
    "        retLabelArray[dataMatrix[:, columnIndex] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retLabelArray[dataMatrix[:, columnIndex] >= threshVal] = -1.0\n",
    "    return retLabelArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建弱分类器，此处使用单层决策树\n",
    "def buildStumpFurther(dataSet, labelSet, D):\n",
    "    # 矩阵化\n",
    "    dataMatrix = np.mat(dataSet)\n",
    "    labelMatrix = np.mat(labelSet).T\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    # 步长\n",
    "    numSteps = 10.0\n",
    "    # init\n",
    "    bestClassifier = {}\n",
    "    bestClassEst = np.mat(np.zeros((m, 1)))\n",
    "    minError = np.inf\n",
    "    # 遍历特征寻找最优特征、阈值\n",
    "    for i in ragne(n):\n",
    "        columnMin = dataMatrix[:, i].min()\n",
    "        columnMax = dataMatrix[:, i].max()\n",
    "        stepSize = (columnMax - columnMin) / numSteps\n",
    "        for j in range(-1, int(numSteps)+1):\n",
    "            for inequal in ['lt', 'gt']:\n",
    "                threshVal = columnMin + float(j) * stepSize\n",
    "                # 获取预测结果\n",
    "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)\n",
    "                # 计算错误率和权重\n",
    "                errArr = np.mat(np.ones((m, 1)))\n",
    "                errArr[predictedVals == labelMatrix] = 0\n",
    "                # 误差权重\n",
    "                weightedError = D.T * errArr\n",
    "                # 单边计算prop_lt就可以，prop_lt+prop_gt=1\n",
    "                if weightedError <= 1 - weightedError:\n",
    "                    minError = weightedError\n",
    "                    bestClassEst = predictedVals.copy()\n",
    "                    bestClassifier['dim'] = 1\n",
    "                    bestClassifier['thresh'] = threshVal\n",
    "                    bestClassifier['ineq'] = inequal\n",
    "                break\n",
    "                \n",
    "        return bestClassifier, minError, bestClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集成训练，构建adaboost分类器\n",
    "def adaBoostTrainDS(dataSet, labelSet, classifierNumberMax):\n",
    "    # 弱分类器初始化\n",
    "    weakClassifierArr = []\n",
    "    # 样本数目\n",
    "    m = np.shape(dataSet)[0]\n",
    "    # init\n",
    "    D = np.mat(np.ones((m, 1)) / m)\n",
    "    preIntegrationLabelsMat = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(classifierNumberMax):\n",
    "        # 寻找最优分类器\n",
    "        bestClassifier, error, preLabelMat = buildStumpFurther(dataSet, labelSet, D)\n",
    "        # 计算分类器权重\n",
    "        alpha = float(0.5 * np.log((1.0 - error) / max(error, 1e-16)))\n",
    "        # 保存权重\n",
    "        bestClassifier['alpha'] = alpha\n",
    "        # 保存分类器\n",
    "        weakClassifierArr.append(bestClassifier)\n",
    "        # 计算样本权重\n",
    "        expon = np.multiply(-1 * alpha * np.mat(labelSet).T, preLabelMat)\n",
    "        D = np.multiply(D, np.exp(expon))\n",
    "        D = D/D.sum()\n",
    "        # 集成分类器估计结果\n",
    "        preIntegrationLabelsMat += alpha * preLabelMat\n",
    "        # 结果错误矩阵\n",
    "        integrationErrors = np.multiply(np.sign(preIntegrationLabelsMat) != np.mat(labelSet).T, np.ones((m, 1)))\n",
    "        # error rate\n",
    "        errorRate = integrationErrors.sum() / m\n",
    "        print(\"集成第 %d 个分类器后的错误率 %f\"% (i, errorRate))\n",
    "        # 错误率为0时终止\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "        \n",
    "        return weakClassifierArr, preIntegrationLabelsMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用adaboost分类器预测\n",
    "def adaClassify(testDataSet, classifierArr):\n",
    "    dataMat = np.mat(testDataSet)\n",
    "    m = np.shape(dataMat)[0]\n",
    "    # init\n",
    "    preIntegrationLabelsMat = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(len(classifierArr[0])):\n",
    "        classEst = stumpClassify(dataMat, classifierArr[0][i]['dim'], \\\n",
    "                                classifierArr[0][i]['thresh'],\\\n",
    "                                classifierArr[0][i]['ineq'])\n",
    "        # 与权重相乘\n",
    "        preIntegrationLabelsMat += classifierArr[0][i]['alpha']*classEst\n",
    "    print('集成后的估计值: %s'% str(preIntegrationLabelsMat))\n",
    "    return np.sign(preIntegrationLabelsMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2.000000    1.000000    38.500000    66.000000    28.000000    3.000000    3.000000    0.000000    2.000000    5.000000    4.000000    4.000000    0.000000    0.000000    0.000000    3.000000    5.000000    45.000000    8.400000    0.000000    0.000000    -1.000000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a1411e192572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelArr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'horseColicTraining2.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclassifierArr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madaBoostTrainDS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-fcb9205ae299>\u001b[0m in \u001b[0;36mloadDataSet\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mlineArr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurLine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mdataSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlineArr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mlabelSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurLine\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2.000000    1.000000    38.500000    66.000000    28.000000    3.000000    3.000000    0.000000    2.000000    5.000000    4.000000    4.000000    0.000000    0.000000    0.000000    3.000000    5.000000    45.000000    8.400000    0.000000    0.000000    -1.000000'"
     ]
    }
   ],
   "source": [
    "datArr, labelArr = loadDataSet('horseColicTraining2.txt')\n",
    "classifierArr = adaBoostTrainDS(datArr, labelArr, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
